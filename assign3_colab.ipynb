{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "gpu_info = !nvidia-smi\n",
        "gpu_info = '\\n'.join(gpu_info)\n",
        "if gpu_info.find('failed') >= 0:\n",
        "  print('Not connected to a GPU')\n",
        "else:\n",
        "  print(gpu_info)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SDuFNRB20D79",
        "outputId": "ae453dff-5d4f-470b-a4e8-6c39b083b110"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Thu Nov 30 16:22:29 2023       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 525.105.17   Driver Version: 525.105.17   CUDA Version: 12.0     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   40C    P8     9W /  70W |      0MiB / 15360MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6i_Okz6RzAKQ",
        "outputId": "04d59eb3-39f4-4149-d488-692fcdb52e32"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting wget\n",
            "  Downloading wget-3.2.zip (10 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: wget\n",
            "  Building wheel for wget (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for wget: filename=wget-3.2-py3-none-any.whl size=9657 sha256=fc1339fc4c6d6ca256e6cf7daa5fbf8f6cde9b5ab67aa631760f444147d9c759\n",
            "  Stored in directory: /root/.cache/pip/wheels/8b/f1/7f/5c94f0a7a505ca1c81cd1d9208ae2064675d97582078e6c769\n",
            "Successfully built wget\n",
            "Installing collected packages: wget\n",
            "Successfully installed wget-3.2\n",
            "\u001b[31mERROR: Could not find a version that satisfies the requirement os (from versions: none)\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: No matching distribution found for os\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: Could not find a version that satisfies the requirement gzip (from versions: none)\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: No matching distribution found for gzip\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: Could not find a version that satisfies the requirement pickle (from versions: none)\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: No matching distribution found for pickle\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: Could not find a version that satisfies the requirement random (from versions: none)\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: No matching distribution found for random\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: Could not find a version that satisfies the requirement re (from versions: none)\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: No matching distribution found for re\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: Could not find a version that satisfies the requirement sys (from versions: none)\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: No matching distribution found for sys\u001b[0m\u001b[31m\n",
            "\u001b[0mRequirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.1.0+cu118)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2023.6.0)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch) (2.1.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (1.23.5)\n"
          ]
        }
      ],
      "source": [
        "!pip install wget\n",
        "!pip install os\n",
        "!pip install gzip\n",
        "!pip install pickle\n",
        "!pip install random\n",
        "!pip install re\n",
        "!pip install sys\n",
        "!pip install torch\n",
        "!pip install numpy\n",
        "\n",
        "import torch\n",
        "import numpy as np\n",
        "import wget\n",
        "import os\n",
        "import gzip\n",
        "import pickle\n",
        "import random\n",
        "import re\n",
        "import sys"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "IMDB_URL = 'http://dlvu.github.io/data/imdb.{}.pkl.gz'\n",
        "IMDB_FILE = 'imdb.{}.pkl.gz'\n",
        "\n",
        "PAD, START, END, UNK = '.pad', '.start', '.end', '.unk'\n",
        "\n",
        "def load_imdb(final=False, val=5000, seed=0, voc=None, char=False):\n",
        "\n",
        "    cst = 'char' if char else 'word'\n",
        "\n",
        "    imdb_url = IMDB_URL.format(cst)\n",
        "    imdb_file = IMDB_FILE.format(cst)\n",
        "\n",
        "    if not os.path.exists(imdb_file):\n",
        "        wget.download(imdb_url)\n",
        "\n",
        "    with gzip.open(imdb_file) as file:\n",
        "        sequences, labels, i2w, w2i = pickle.load(file)\n",
        "\n",
        "    if voc is not None and voc < len(i2w):\n",
        "        nw_sequences = {}\n",
        "\n",
        "        i2w = i2w[:voc]\n",
        "        w2i = {w: i for i, w in enumerate(i2w)}\n",
        "\n",
        "        mx, unk = voc, w2i['.unk']\n",
        "        for key, seqs in sequences.items():\n",
        "            nw_sequences[key] = []\n",
        "            for seq in seqs:\n",
        "                seq = [s if s < mx else unk for s in seq]\n",
        "                nw_sequences[key].append(seq)\n",
        "\n",
        "        sequences = nw_sequences\n",
        "\n",
        "    if final:\n",
        "        return (sequences['train'], labels['train']), (sequences['test'], labels['test']), (i2w, w2i), 2\n",
        "\n",
        "    # Make a validation split\n",
        "    random.seed(seed)\n",
        "\n",
        "    x_train, y_train = [], []\n",
        "    x_val, y_val = [], []\n",
        "\n",
        "    val_ind = set( random.sample(range(len(sequences['train'])), k=val) )\n",
        "    for i, (s, l) in enumerate(zip(sequences['train'], labels['train'])):\n",
        "        if i in val_ind:\n",
        "            x_val.append(s)\n",
        "            y_val.append(l)\n",
        "        else:\n",
        "            x_train.append(s)\n",
        "            y_train.append(l)\n",
        "\n",
        "    return (x_train, y_train), \\\n",
        "           (x_val, y_val), \\\n",
        "           (i2w, w2i), 2\n",
        "\n",
        "\n",
        "def gen_sentence(sent, g):\n",
        "\n",
        "    symb = '_[a-z]*'\n",
        "\n",
        "    while True:\n",
        "\n",
        "        match = re.search(symb, sent)\n",
        "        if match is None:\n",
        "            return sent\n",
        "\n",
        "        s = match.span()\n",
        "        sent = sent[:s[0]] + random.choice(g[sent[s[0]:s[1]]]) + sent[s[1]:]\n",
        "\n",
        "def gen_dyck(p):\n",
        "    open = 1\n",
        "    sent = '('\n",
        "    while open > 0:\n",
        "        if random.random() < p:\n",
        "            sent += '('\n",
        "            open += 1\n",
        "        else:\n",
        "            sent += ')'\n",
        "            open -= 1\n",
        "\n",
        "    return sent\n",
        "\n",
        "def gen_ndfa(p):\n",
        "\n",
        "    word = random.choice(['abc!', 'uvw!', 'klm!'])\n",
        "\n",
        "    s = ''\n",
        "    while True:\n",
        "        if random.random() < p:\n",
        "            return 's' + s + 's'\n",
        "        else:\n",
        "            s+= word\n",
        "\n",
        "def load_brackets(n=50_000, seed=0):\n",
        "    return load_toy(n, char=True, seed=seed, name='dyck')\n",
        "\n",
        "def load_ndfa(n=50_000, seed=0):\n",
        "    return load_toy(n, char=True, seed=seed, name='ndfa')\n",
        "\n",
        "def load_toy(n=50_000, char=True, seed=0, name='lang'):\n",
        "\n",
        "    random.seed(0)\n",
        "\n",
        "    if name == 'lang':\n",
        "        sent = '_s'\n",
        "\n",
        "        toy = {\n",
        "            '_s': ['_s _adv', '_np _vp', '_np _vp _prep _np', '_np _vp ( _prep _np )', '_np _vp _con _s' , '_np _vp ( _con _s )'],\n",
        "            '_adv': ['briefly', 'quickly', 'impatiently'],\n",
        "            '_np': ['a _noun', 'the _noun', 'a _adj _noun', 'the _adj _noun'],\n",
        "            '_prep': ['on', 'with', 'to'],\n",
        "            '_con' : ['while', 'but'],\n",
        "            '_noun': ['mouse', 'bunny', 'cat', 'dog', 'man', 'woman', 'person'],\n",
        "            '_vp': ['walked', 'walks', 'ran', 'runs', 'goes', 'went'],\n",
        "            '_adj': ['short', 'quick', 'busy', 'nice', 'gorgeous']\n",
        "        }\n",
        "\n",
        "        sentences = [ gen_sentence(sent, toy) for _ in range(n)]\n",
        "        sentences.sort(key=lambda s : len(s))\n",
        "\n",
        "    elif name == 'dyck':\n",
        "\n",
        "        sentences = [gen_dyck(7./16.) for _ in range(n)]\n",
        "        sentences.sort(key=lambda s: len(s))\n",
        "\n",
        "    elif name == 'ndfa':\n",
        "\n",
        "        sentences = [gen_ndfa(1./4.) for _ in range(n)]\n",
        "        sentences.sort(key=lambda s: len(s))\n",
        "\n",
        "    else:\n",
        "        raise Exception(name)\n",
        "\n",
        "    tokens = set()\n",
        "    for s in sentences:\n",
        "\n",
        "        if char:\n",
        "            for c in s:\n",
        "                tokens.add(c)\n",
        "        else:\n",
        "            for w in s.split():\n",
        "                tokens.add(w)\n",
        "\n",
        "    i2t = [PAD, START, END, UNK] + list(tokens)\n",
        "    t2i = {t:i for i, t in enumerate(i2t)}\n",
        "\n",
        "    sequences = []\n",
        "    for s in sentences:\n",
        "        if char:\n",
        "            tok = list(s)\n",
        "        else:\n",
        "            tok = s.split()\n",
        "        sequences.append([t2i[t] for t in tok])\n",
        "\n",
        "    return sequences, (i2t, t2i)"
      ],
      "metadata": {
        "id": "vg67Q81XzZVP"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ukVNsGzvzAKV",
        "outputId": "4bd51d9d-8c11-41b3-f3bf-f3570381185f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x_train: 20000\n",
            "y_train: 20000\n"
          ]
        }
      ],
      "source": [
        "# load data\n",
        "(x_train, y_train), (x_val, y_val), (i2w, w2i), numcls = load_imdb(final=False) # if final is True, train and test set is returned. Else validation data\n",
        "\n",
        "print('x_train:', len(x_train))\n",
        "print('y_train:', len(y_train))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "xbph7n_LzAKd"
      },
      "outputs": [],
      "source": [
        "def padding(x, y, w2i, batch_size = 16):\n",
        "\n",
        "    batches_x = []\n",
        "    batches_y = []\n",
        "\n",
        "    # step over x met steps of batch_size\n",
        "    for i in range(0, len(x), batch_size):\n",
        "\n",
        "        start = i\n",
        "        end = i + batch_size\n",
        "\n",
        "        # get the batch\n",
        "        batch_x = x[start:end]\n",
        "        batch_y = y[start:end]\n",
        "\n",
        "        batch = []\n",
        "        for i, sentence in enumerate(batch_x):\n",
        "            longest_sentence = max([len(sentence) for sentence in batch_x])\n",
        "            if len(sentence) < longest_sentence:\n",
        "                sentence += [w2i['pad']] * (longest_sentence - len(sentence))\n",
        "\n",
        "            # print(len(sentence))\n",
        "            batch.append(sentence)\n",
        "\n",
        "        batches_x.append(batch)\n",
        "        batches_y.append(batch_y)\n",
        "\n",
        "    # transform all batches to tensors\n",
        "    batches_x = [torch.tensor(batch, dtype = torch.long) for batch in batches_x]\n",
        "    batches_y = [torch.tensor(batch, dtype = torch.long) for batch in batches_y]\n",
        "\n",
        "    return batches_x, batches_y\n",
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "UiTlP4PezAKe"
      },
      "outputs": [],
      "source": [
        "# create batches\n",
        "batch_size = 16\n",
        "batches_x, batches_y = padding(x_train, y_train, w2i, batch_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "jI_GaCjjzAKf"
      },
      "outputs": [],
      "source": [
        "class MLP(torch.nn.Module):\n",
        "\n",
        "    def __init__(self, w2i, embedding_dim = 300, hidden_size = 300):\n",
        "        super(MLP, self).__init__()\n",
        "        num_embeddings = len(w2i)\n",
        "        self.embedding =  torch.nn.Embedding(num_embeddings, embedding_dim)\n",
        "        self.hidden = torch.nn.Linear(embedding_dim, hidden_size)\n",
        "        self.output = torch.nn.Linear(hidden_size, 2)\n",
        "\n",
        "    def forward(self, x):\n",
        "        emb = self.embedding(x)\n",
        "        k = self.hidden(emb)\n",
        "        h = torch.nn.functional.relu(k)\n",
        "        o, _ = torch.max(h, dim=1)\n",
        "        y = self.output(o)\n",
        "        return y\n",
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "48Vq0QLHzAKg"
      },
      "outputs": [],
      "source": [
        "def train(batches_x, batches_y, model, epochs = 5, optimizer = 'Adam', lr=0.001):\n",
        "\n",
        "    # Check if GPU is available and set the device accordingly\n",
        "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "    print(\"Using device:\", device)\n",
        "\n",
        "    model = model.to(device)\n",
        "\n",
        "    batches_x = [batch.to(device) for batch in batches_x]\n",
        "    batches_y = [batch.to(device) for batch in batches_y]\n",
        "\n",
        "    if optimizer == 'Adam':\n",
        "        optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
        "    elif optimizer == 'SGD':\n",
        "        optimizer = torch.optim.SGD(model.parameters(), lr=lr)\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "\n",
        "        losses = []\n",
        "        accuracies = []\n",
        "        for i, batch in enumerate(batches_x):\n",
        "            if i % 100 == 0: print('Batch number: ',i)\n",
        "            predicted_y = model(batch)\n",
        "            loss = torch.nn.functional.cross_entropy(predicted_y, batches_y[i])\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            losses.append(loss.item())\n",
        "\n",
        "            # get index of the max value (0 or 1)\n",
        "            predicted_y = predicted_y.argmax(dim=1)\n",
        "\n",
        "            # calculate accuracy: number of correct predictions / number of predictions\n",
        "            n_correct = (predicted_y == batches_y[i]).sum().item()\n",
        "            accuracy = n_correct / len(predicted_y)\n",
        "            accuracies.append(accuracy)\n",
        "\n",
        "        print('Epoch: ', epoch, 'Loss: ', np.mean(losses), 'Accuracy: ', np.mean(accuracies))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "5EKhmJa0zAKg"
      },
      "outputs": [],
      "source": [
        "#model = MLP(w2i)\n",
        "#train(batches_x, batches_y, model, epochs = 10, optimizer = 'Adam', lr=0.001)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Elman(torch.nn.Module):\n",
        "    def __init__(self, insize=300, outsize=300, hsize=300):\n",
        "        super().__init__()\n",
        "        self.lin1 = torch.nn.Linear(insize + hsize, hsize)  # Input-to-hidden layer\n",
        "        self.lin2 = torch.nn.Linear(hsize, outsize)  # Hidden-to-output layer\n",
        "\n",
        "    def forward(self, x, hidden=None):\n",
        "        batch_size, sequence_size, embedding_size = x.size()\n",
        "        if hidden is None:\n",
        "            hidden = torch.zeros(batch_size, embedding_size, dtype=torch.float, device=x.device)  # Ensure hidden is on the same device\n",
        "\n",
        "        outs = []\n",
        "        for i in range(sequence_size):\n",
        "            inp = torch.cat([x[:, i, :], hidden], dim=1)\n",
        "            hidden = torch.nn.functional.relu(self.lin1(inp))\n",
        "            out = self.lin2(hidden)\n",
        "            outs.append(out[:, None, :])\n",
        "\n",
        "        return torch.cat(outs, dim=1), hidden"
      ],
      "metadata": {
        "id": "lCjSuFQc9YY3"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MLP2(torch.nn.Module):\n",
        "\n",
        "    def __init__(self, w2i, embedding_dim = 300, hidden_size = 300):\n",
        "        super(MLP2, self).__init__()\n",
        "        num_embeddings = len(w2i)\n",
        "        self.embedding =  torch.nn.Embedding(num_embeddings, embedding_dim)\n",
        "        self.hidden = Elman(embedding_dim, hidden_size)\n",
        "        self.output = torch.nn.Linear(hidden_size, 2)\n",
        "\n",
        "    def forward(self, x):\n",
        "        emb = self.embedding(x)\n",
        "        tensors, hidden_layer = self.hidden(emb)\n",
        "        h = torch.nn.functional.relu(tensors)\n",
        "        o, _ = torch.max(h, dim=1)\n",
        "        y = self.output(o)\n",
        "        return y"
      ],
      "metadata": {
        "id": "iEqLvklQ9f3_"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = MLP2(w2i)\n",
        "train(batches_x, batches_y, model, epochs = 10, optimizer = 'Adam', lr=0.001)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-fO2Zgyx9icJ",
        "outputId": "c88e3ddf-1fdb-4f83-bda3-1916f1707985"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n",
            "Batch number:  0\n",
            "Batch number:  100\n",
            "Batch number:  200\n",
            "Batch number:  300\n",
            "Batch number:  400\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    },
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}