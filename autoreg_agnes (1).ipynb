{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "_FEGxe1GeHd5"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import numpy as np\n",
        "import torch.distributions as dist\n",
        "from torch.nn import functional as F\n",
        "import random\n",
        "import matplotlib.pyplot as plt\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "import numpy as np\n",
        "import re\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "brackets = False"
      ],
      "metadata": {
        "id": "jrWxydWrds3E"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "IMDB_URL = 'http://dlvu.github.io/data/imdb.{}.pkl.gz'\n",
        "IMDB_FILE = 'imdb.{}.pkl.gz'\n",
        "\n",
        "PAD, START, END, UNK = '.pad', '.start', '.end', '.unk'\n",
        "\n",
        "def load_imdb(final=False, val=5000, seed=0, voc=None, char=False):\n",
        "\n",
        "    cst = 'char' if char else 'word'\n",
        "\n",
        "    imdb_url = IMDB_URL.format(cst)\n",
        "    imdb_file = IMDB_FILE.format(cst)\n",
        "\n",
        "    if not os.path.exists(imdb_file):\n",
        "        wget.download(imdb_url)\n",
        "\n",
        "    with gzip.open(imdb_file) as file:\n",
        "        sequences, labels, i2w, w2i = pickle.load(file)\n",
        "\n",
        "    if voc is not None and voc < len(i2w):\n",
        "        nw_sequences = {}\n",
        "\n",
        "        i2w = i2w[:voc]\n",
        "        w2i = {w: i for i, w in enumerate(i2w)}\n",
        "\n",
        "        mx, unk = voc, w2i['.unk']\n",
        "        for key, seqs in sequences.items():\n",
        "            nw_sequences[key] = []\n",
        "            for seq in seqs:\n",
        "                seq = [s if s < mx else unk for s in seq]\n",
        "                nw_sequences[key].append(seq)\n",
        "\n",
        "        sequences = nw_sequences\n",
        "\n",
        "    if final:\n",
        "        return (sequences['train'], labels['train']), (sequences['test'], labels['test']), (i2w, w2i), 2\n",
        "\n",
        "    # Make a validation split\n",
        "    random.seed(seed)\n",
        "\n",
        "    x_train, y_train = [], []\n",
        "    x_val, y_val = [], []\n",
        "\n",
        "    val_ind = set( random.sample(range(len(sequences['train'])), k=val) )\n",
        "    for i, (s, l) in enumerate(zip(sequences['train'], labels['train'])):\n",
        "        if i in val_ind:\n",
        "            x_val.append(s)\n",
        "            y_val.append(l)\n",
        "        else:\n",
        "            x_train.append(s)\n",
        "            y_train.append(l)\n",
        "\n",
        "    return (x_train, y_train), \\\n",
        "           (x_val, y_val), \\\n",
        "           (i2w, w2i), 2\n",
        "\n",
        "\n",
        "def gen_sentence(sent, g):\n",
        "\n",
        "    symb = '_[a-z]*'\n",
        "\n",
        "    while True:\n",
        "\n",
        "        match = re.search(symb, sent)\n",
        "        if match is None:\n",
        "            return sent\n",
        "\n",
        "        s = match.span()\n",
        "        sent = sent[:s[0]] + random.choice(g[sent[s[0]:s[1]]]) + sent[s[1]:]\n",
        "\n",
        "def gen_dyck(p):\n",
        "    open = 1\n",
        "    sent = '('\n",
        "    while open > 0:\n",
        "        if random.random() < p:\n",
        "            sent += '('\n",
        "            open += 1\n",
        "        else:\n",
        "            sent += ')'\n",
        "            open -= 1\n",
        "\n",
        "    return sent\n",
        "\n",
        "def gen_ndfa(p):\n",
        "\n",
        "    word = random.choice(['abc!', 'uvw!', 'klm!'])\n",
        "\n",
        "    s = ''\n",
        "    while True:\n",
        "        if random.random() < p:\n",
        "            return 's' + s + 's'\n",
        "        else:\n",
        "            s+= word\n",
        "\n",
        "def load_brackets(n=50_000, seed=0):\n",
        "    return load_toy(n, char=True, seed=seed, name='dyck')\n",
        "\n",
        "def load_ndfa(n=50_000, seed=0):\n",
        "    return load_toy(n, char=True, seed=seed, name='ndfa')\n",
        "\n",
        "def load_toy(n=50_000, char=True, seed=0, name='lang'):\n",
        "\n",
        "    random.seed(0)\n",
        "\n",
        "    if name == 'lang':\n",
        "        sent = '_s'\n",
        "\n",
        "        toy = {\n",
        "            '_s': ['_s _adv', '_np _vp', '_np _vp _prep _np', '_np _vp ( _prep _np )', '_np _vp _con _s' , '_np _vp ( _con _s )'],\n",
        "            '_adv': ['briefly', 'quickly', 'impatiently'],\n",
        "            '_np': ['a _noun', 'the _noun', 'a _adj _noun', 'the _adj _noun'],\n",
        "            '_prep': ['on', 'with', 'to'],\n",
        "            '_con' : ['while', 'but'],\n",
        "            '_noun': ['mouse', 'bunny', 'cat', 'dog', 'man', 'woman', 'person'],\n",
        "            '_vp': ['walked', 'walks', 'ran', 'runs', 'goes', 'went'],\n",
        "            '_adj': ['short', 'quick', 'busy', 'nice', 'gorgeous']\n",
        "        }\n",
        "\n",
        "        sentences = [ gen_sentence(sent, toy) for _ in range(n)]\n",
        "        sentences.sort(key=lambda s : len(s))\n",
        "\n",
        "    elif name == 'dyck':\n",
        "\n",
        "        sentences = [gen_dyck(7./16.) for _ in range(n)]\n",
        "        sentences.sort(key=lambda s: len(s))\n",
        "\n",
        "    elif name == 'ndfa':\n",
        "\n",
        "        sentences = [gen_ndfa(1./4.) for _ in range(n)]\n",
        "        sentences.sort(key=lambda s: len(s))\n",
        "\n",
        "    else:\n",
        "        raise Exception(name)\n",
        "\n",
        "    tokens = set()\n",
        "    for s in sentences:\n",
        "\n",
        "        if char:\n",
        "            for c in s:\n",
        "                tokens.add(c)\n",
        "        else:\n",
        "            for w in s.split():\n",
        "                tokens.add(w)\n",
        "\n",
        "    i2t = [PAD, START, END, UNK] + list(tokens)\n",
        "    t2i = {t:i for i, t in enumerate(i2t)}\n",
        "\n",
        "    sequences = []\n",
        "    for s in sentences:\n",
        "        if char:\n",
        "            tok = list(s)\n",
        "        else:\n",
        "            tok = s.split()\n",
        "        sequences.append([t2i[t] for t in tok])\n",
        "\n",
        "    return sequences, (i2t, t2i)"
      ],
      "metadata": {
        "id": "jr3jw6ndev1t"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def padding_and_split(x, w2i, max_tokens_per_batch=1000, split_ratio=0.2):\n",
        "    # Split data into training and validation sets\n",
        "    x_train, x_val = train_test_split(x, test_size=split_ratio, random_state=42)\n",
        "\n",
        "    def create_batches(data):\n",
        "        # Sort sequences by length\n",
        "        sorted_data = sorted(data, key=len)\n",
        "        batches = []\n",
        "        batch = []\n",
        "        tokens_in_batch = 0\n",
        "\n",
        "        for sentence in sorted_data:\n",
        "            sentence = [w2i['.start']] + sentence + [w2i['.end']]  # Add start/end tokens\n",
        "            sentence_len = len(sentence)\n",
        "\n",
        "            if tokens_in_batch + sentence_len > max_tokens_per_batch:\n",
        "                # If adding this sentence exceeds max tokens per batch, start a new batch\n",
        "                batches.append(batch)\n",
        "                batch = []\n",
        "                tokens_in_batch = 0\n",
        "\n",
        "            batch.append(sentence)\n",
        "            tokens_in_batch += sentence_len\n",
        "\n",
        "        # Add the last batch if it's not empty\n",
        "        if batch:\n",
        "            batches.append(batch)\n",
        "\n",
        "        # Pad each batch\n",
        "        for i, batch in enumerate(batches):\n",
        "            longest_sentence = max([len(sentence) for sentence in batch])\n",
        "            for j, sentence in enumerate(batch):\n",
        "                if len(sentence) < longest_sentence:\n",
        "                    batches[i][j] += [w2i['.pad']] * (longest_sentence - len(sentence))\n",
        "\n",
        "        # Shuffle the list of batches\n",
        "        np.random.shuffle(batches)\n",
        "\n",
        "        # Convert batches to tensors\n",
        "        batches = [torch.tensor(batch, dtype=torch.long) for batch in batches]\n",
        "\n",
        "        return batches\n",
        "\n",
        "    # Create batches for training and validation sets\n",
        "    batch_x_train = create_batches(x_train)\n",
        "    batch_x_val = create_batches(x_val)\n",
        "\n",
        "    return batch_x_train, batch_x_val"
      ],
      "metadata": {
        "id": "hlRPRct2xTL2"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dDXIh1WneHd7",
        "outputId": "d1f5f93c-90ac-427e-e4b5-8f04f0a1a19c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of training batches: 1993\n",
            "Number of validation batches: 492\n",
            "Shape of first training batch: torch.Size([17, 56])\n",
            "Shape of first validation batch: torch.Size([9, 107])\n"
          ]
        }
      ],
      "source": [
        "# Example usage\n",
        "if brackets:\n",
        "  x_train, (i2w, w2i) = load_brackets(n=150_000)\n",
        "\n",
        "else:\n",
        "  x_train, (i2w, w2i) = load_toy(n=50_000, char=True)\n",
        "\n",
        "batch_x_train, batch_x_val = padding_and_split(x_train, w2i)\n",
        "\n",
        "# Print lengths and shapes to verify\n",
        "print(\"Number of training batches:\", len(batch_x_train))\n",
        "print(\"Number of validation batches:\", len(batch_x_val))\n",
        "print(\"Shape of first training batch:\", batch_x_train[0].shape)\n",
        "print(\"Shape of first validation batch:\", batch_x_val[0].shape)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "PXB1SP6ceHd7"
      },
      "outputs": [],
      "source": [
        "class AutoregressiveLSTM(nn.Module):\n",
        "    def __init__(self, vocab_size, embedding_dim, hidden_size, num_layers, dropout_rate=0.2):\n",
        "        super(AutoregressiveLSTM, self).__init__()\n",
        "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
        "        #self.dropout = nn.Dropout(dropout_rate)  # Dropout layer after embedding\n",
        "        self.lstm = nn.LSTM(embedding_dim, hidden_size, num_layers, batch_first=True, dropout=dropout_rate)\n",
        "        self.linear = nn.Linear(hidden_size, vocab_size)\n",
        "\n",
        "    def forward(self, x):\n",
        "        embedded = self.embedding(x)\n",
        "        #embedded = self.dropout(embedded)\n",
        "        lstm_out, _ = self.lstm(embedded)\n",
        "        output = self.linear(lstm_out)\n",
        "        return output\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "AI0Fv9YHeHd8"
      },
      "outputs": [],
      "source": [
        "# Instantiate the model\n",
        "embedding_dim = 32\n",
        "hidden_size = 16\n",
        "num_layers = 3\n",
        "\n",
        "model = AutoregressiveLSTM(len(w2i), embedding_dim, hidden_size, num_layers)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "WebtW5YueHd8"
      },
      "outputs": [],
      "source": [
        "def sample(lnprobs, temperature=0.5):\n",
        "    \"\"\"\n",
        "    Sample an element from a categorical distribution\n",
        "    :param lnprobs: Outcome logits\n",
        "    :param temperature: Sampling temperature. 1.0 follows the given\n",
        "    distribution, 0.0 returns the maximum probability element.\n",
        "    :return: The index of the sampled element.\n",
        "    \"\"\"\n",
        "    if temperature == 0.0:\n",
        "        return lnprobs.argmax()\n",
        "    p = F.softmax(lnprobs / temperature, dim=0)\n",
        "    cd = dist.Categorical(p)\n",
        "    return cd.sample()\n",
        "\n",
        "def generate_sequences(model, max_length = 20):\n",
        "    # Maximum sequence length\n",
        "    sequences = []\n",
        "\n",
        "    for i in range(100):\n",
        "\n",
        "        seq = [w2i['.start'], w2i['('], w2i['('], w2i[')']]\n",
        "        # Convert the seed sequence to a tensor and add a singleton batch dimension\n",
        "        seed_input = torch.tensor([seq], dtype=torch.long)\n",
        "\n",
        "\n",
        "        # Generate sequences\n",
        "        for _ in range(max_length):\n",
        "\n",
        "            # Forward pass\n",
        "            output = model(seed_input)\n",
        "\n",
        "            # Get the probabilities for the next token\n",
        "            probabilities = torch.softmax(output[0, -1, :], dim=-1)\n",
        "\n",
        "            # Sample the next token with hel of distribution\n",
        "            next_token = sample(probabilities)\n",
        "            # Append the sampled token to the existing sequence\n",
        "            seq.append(next_token)\n",
        "            # If the end token is sampled, break the loop\n",
        "            if next_token == w2i['.end']:\n",
        "                break\n",
        "\n",
        "            # Prepare the input for the next iteration\n",
        "            seed_input = torch.tensor([seq], dtype=torch.long)\n",
        "\n",
        "        # Convert the sequence back to words\n",
        "        generated_sequence = [i2w[token] for token in seq]\n",
        "\n",
        "        # check if the sequence is valid\n",
        "        sequences.append(generated_sequence)\n",
        "\n",
        "    return sequences\n",
        "\n",
        "\n",
        "# check if the sequence is valid\n",
        "def check_sequence(sequence):\n",
        "    stack = []\n",
        "    for token in sequence:\n",
        "        if token == '(':\n",
        "            stack.append(token)\n",
        "        elif token == ')':\n",
        "            if len(stack) == 0:\n",
        "                return False\n",
        "            stack.pop()\n",
        "    return len(stack) == 0"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def train(model, batch_x, batch_x_val, num_epochs=10, learning_rate=0.001, clip_value=1):\n",
        "    losses = []\n",
        "    accuracies = []\n",
        "    validation_accuracies = []\n",
        "\n",
        "    weights = torch.ones(len(w2i))\n",
        "    weights[w2i['.pad']] = 0\n",
        "    criterion = nn.CrossEntropyLoss(weight=weights, reduction='sum')\n",
        "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        model.train()  # Ensure the model is in training mode\n",
        "        total_loss = 0\n",
        "        total_correct = 0\n",
        "        total_tokens = 0\n",
        "\n",
        "        # Training loop\n",
        "        for batch in batch_x:\n",
        "            optimizer.zero_grad()\n",
        "            input_batch = batch[:, :-1]\n",
        "            target_batch = batch[:, 1:]\n",
        "            output = model(input_batch)\n",
        "\n",
        "            # Calculate loss\n",
        "            n_tokens = target_batch.numel()\n",
        "            loss = criterion(output.reshape(-1, len(w2i)), target_batch.reshape(-1)) / n_tokens\n",
        "\n",
        "            # Backward pass and optimization\n",
        "            loss.backward()\n",
        "\n",
        "            # Apply gradient clipping\n",
        "            torch.nn.utils.clip_grad_norm_(model.parameters(), clip_value)\n",
        "            optimizer.step()\n",
        "\n",
        "            # Update total loss and accuracy\n",
        "            total_loss += loss.item()\n",
        "            _, predicted = torch.max(output.data, 2)\n",
        "            total_correct += (predicted == target_batch).sum().item()\n",
        "            total_tokens += n_tokens\n",
        "\n",
        "        # Compute average loss and accuracy for the epoch\n",
        "        average_loss = total_loss / len(batch_x)\n",
        "        average_accuracy = total_correct / total_tokens\n",
        "        losses.append(average_loss)\n",
        "        accuracies.append(average_accuracy)\n",
        "\n",
        "        # Validation loop\n",
        "        model.eval()  # Put the model in evaluation mode\n",
        "        val_total_loss = 0\n",
        "        val_total_correct = 0\n",
        "        val_total_tokens = 0\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for val_batch in batch_x_val:\n",
        "                val_input_batch = val_batch[:, :-1]\n",
        "                val_target_batch = val_batch[:, 1:]\n",
        "                val_output = model(val_input_batch)\n",
        "\n",
        "                # Calculate validation loss\n",
        "                n_val_tokens = val_target_batch.numel()\n",
        "\n",
        "                # Update total validation loss and accuracy\n",
        "                _, val_predicted = torch.max(val_output.data, 2)\n",
        "                val_total_correct += (val_predicted == val_target_batch).sum().item()\n",
        "                val_total_tokens += n_val_tokens\n",
        "\n",
        "        # Compute average validation loss and accuracy\n",
        "        average_val_accuracy = val_total_correct / val_total_tokens\n",
        "        validation_accuracies.append(average_val_accuracy)\n",
        "\n",
        "        # Print epoch summary\n",
        "        print(f'Epoch {epoch + 1}/{num_epochs}, Loss: {average_loss}, Accuracy: {average_accuracy}, Validation Accuracy: {average_val_accuracy}')\n",
        "\n",
        "        if brackets:\n",
        "          # generate sequences and get perc correct\n",
        "          sequences = generate_sequences(model)\n",
        "          valid_generated = [check_sequence(sequence) for sequence in sequences]\n",
        "          valid_generated = sum(valid_generated) / len(valid_generated)\n",
        "          print(f'generation accuracy: {valid_generated}')\n",
        "\n",
        "    return model, losses, validation_accuracies\n"
      ],
      "metadata": {
        "id": "Ltp8R6EJqLmX"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# def train(model, batch_x, batch_x_val, num_epochs=10, learning_rate=0.001):\n",
        "#     losses = []\n",
        "#     accuracies = []\n",
        "#     validation_accuracies = []\n",
        "\n",
        "#     weights = torch.ones(len(w2i))\n",
        "#     weights[w2i['.pad']] = 0\n",
        "#     criterion = nn.CrossEntropyLoss(weight=weights, reduction='sum')\n",
        "#     optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "#     for epoch in range(num_epochs):\n",
        "#         batch_loss = 0\n",
        "#         batch_accuracy = 0\n",
        "\n",
        "#         # Iterate over batches\n",
        "#         for batch in batch_x:\n",
        "#             optimizer.zero_grad()  # Zero the gradients\n",
        "#             input_batch = batch[:, :-1]  # Input sequence (exclude last token)\n",
        "#             target_batch = batch[:, 1:]  # Target sequence (exclude first token)\n",
        "\n",
        "#             # Forward pass\n",
        "#             output = model(input_batch)\n",
        "\n",
        "#             # Calculate loss\n",
        "#             n_tokens = len(target_batch.reshape(-1))\n",
        "#             loss = criterion(output.reshape(-1, len(w2i)), target_batch.reshape(-1)) / n_tokens\n",
        "\n",
        "#             # Backward pass and optimization\n",
        "#             loss.backward()\n",
        "#             optimizer.step()\n",
        "\n",
        "#             # accuracy\n",
        "#             _, predicted = torch.max(output.data, 2)\n",
        "#             correct = (predicted == target_batch).sum().item()\n",
        "#             accuracy = correct / (predicted.shape[0] * predicted.shape[1])\n",
        "\n",
        "#             # append loss and accuracy to total for epoch\n",
        "#             batch_loss += loss.item()\n",
        "#             batch_accuracy += accuracy\n",
        "\n",
        "#         # Print the average loss for the epoch\n",
        "#         average_loss = batch_loss / len(batch_x)\n",
        "#         average_accuracy = batch_accuracy / len(batch_x)\n",
        "\n",
        "#         # append loss to list\n",
        "#         losses.append(average_loss)\n",
        "#         accuracies.append(average_accuracy)\n",
        "\n",
        "#         if brackets:\n",
        "#           # generate sequences and get perc correct\n",
        "#           sequences = generate_sequences(model)\n",
        "#           valid_generated = [check_sequence(sequence) for sequence in sequences]\n",
        "#           valid_generated = sum(valid_generated) / len(valid_generated)\n",
        "#           print(f'generation accuracy: {valid_generated}')\n",
        "\n",
        "#         # Validation\n",
        "#         model.eval()  # Put the model in evaluation mode\n",
        "#         val_correct = 0\n",
        "#         val_total = 0\n",
        "\n",
        "#         with torch.no_grad():  # No need to track gradients during validation\n",
        "#             for val_batch in batch_x_val:\n",
        "#                 val_input_batch = val_batch[:, :-1]\n",
        "#                 val_target_batch = val_batch[:, 1:]\n",
        "\n",
        "#                 val_output = model(val_input_batch)\n",
        "\n",
        "#                 # Calculate accuracy\n",
        "#                 _, val_predicted = torch.max(val_output.data, 2)\n",
        "#                 val_correct += (val_predicted == val_target_batch).sum().item()\n",
        "#                 val_total += val_predicted.numel()\n",
        "\n",
        "#         val_accuracy = val_correct / val_total\n",
        "#         validation_accuracies.append(val_accuracy)\n",
        "#         model.train()\n",
        "\n",
        "#         print(f'Epoch {epoch + 1}/{num_epochs}, Loss: {average_loss}, Accuracy: {average_accuracy}, Validation Accuracy: {val_accuracy}')\n",
        "\n",
        "\n",
        "#     return model, losses, validation_accuracies"
      ],
      "metadata": {
        "id": "B6QWQfyebGUQ"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hqMOxRt3eHd9",
        "outputId": "482029a8-77bf-4052-b91a-598c48617ef8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50, Loss: 3.0088205501414755, Accuracy: 0.18403935542042935, Validation Accuracy: 0.20135510399685078\n",
            "Epoch 2/50, Loss: 2.708093781239174, Accuracy: 0.22269971996452673, Validation Accuracy: 0.3314100013264359\n"
          ]
        }
      ],
      "source": [
        "# Initiate hyper-parametric values\n",
        "learning_rate = 0.0001\n",
        "num_epochs = 50\n",
        "\n",
        "# Train the model\n",
        "model, losses, accuracies = train(model, batch_x_train, batch_x_val, num_epochs, learning_rate)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NMVzxrRgeHd9"
      },
      "outputs": [],
      "source": [
        "# plot losses\n",
        "plt.figure(figsize=(10, 5))  # Set the figure size (optional)\n",
        "plt.plot(losses, marker='o')  # Plot losses, 'o' denotes the marker style\n",
        "plt.title('Training Loss per Epoch')  # Title of the plot\n",
        "plt.xlabel('Epoch')  # Label for the x-axis\n",
        "plt.ylabel('Loss')  # Label for the y-axis\n",
        "plt.grid(True)  # Add\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a_ptFTFreHd9"
      },
      "outputs": [],
      "source": [
        "# plot validation accuracies\n",
        "plt.clf()\n",
        "plt.figure(figsize=(10, 5))  # Set the figure size (optional)\n",
        "plt.plot(accuracies, marker='o')  # Plot losses, 'o' denotes the marker style\n",
        "plt.title('Validation accuracy per Epoch')  # Title of the plot\n",
        "plt.xlabel('Epoch')  # Label for the x-axis\n",
        "plt.ylabel('Accuracy')  # Label for the y-axis\n",
        "plt.grid(True)  # Add\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    },
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}