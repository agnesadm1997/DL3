{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import *\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def padding(x, w2i, batch_size=15):\n",
    "    batches_x = []\n",
    "\n",
    "    # step over x met steps of batch_size\n",
    "    for i in range(0, len(x), batch_size):\n",
    "\n",
    "        start = i\n",
    "        end = i + batch_size\n",
    "\n",
    "        # get the batch\n",
    "        batch_x = x[start:end]\n",
    "        batch = []\n",
    "\n",
    "        # Adding start/end\n",
    "        for sentence in batch_x:\n",
    "            sentence.insert(0, w2i['.start'])\n",
    "            sentence.append(w2i['.end'])\n",
    "\n",
    "        for i, sentence in enumerate(batch_x):\n",
    "            longest_sentence = max([len(sentence) for sentence in batch_x])\n",
    "            if len(sentence) < longest_sentence:\n",
    "                sentence += [w2i['.pad']] * (longest_sentence - len(sentence))\n",
    "            # print(len(sentence))\n",
    "            batch.append(sentence)\n",
    "\n",
    "        batches_x.append(batch)\n",
    "\n",
    "    # transform all batches to tensors\n",
    "    batches_x = [torch.tensor(batch, dtype=torch.long) for batch in batches_x]\n",
    "\n",
    "    return batches_x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, (i2w, w2i) = load_ndfa(n=150_000)\n",
    "batches_x = padding(x_train, w2i)\n",
    "\n",
    "# Set up the model\n",
    "class AutoregressiveLSTM(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim=32, hidden_size=16, num_layers=1):\n",
    "        super(AutoregressiveLSTM, self).__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.lstm = nn.LSTM(embedding_dim, hidden_size, num_layers, batch_first=True)\n",
    "        self.linear = nn.Linear(hidden_size, vocab_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        embedded = self.embedding(x)\n",
    "        lstm_out, _ = self.lstm(embedded)\n",
    "        output = self.linear(lstm_out)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def train(batches_x, model, epochs=10, lr=0.001, optimizer='Adam', do_seed=False):\n",
    "\n",
    "    if optimizer == 'Adam':\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    elif optimizer == 'SGD':\n",
    "        optimizer = torch.optim.SGD(model.parameters(), lr=lr)\n",
    "      \n",
    "    # Define loss function and optimizer\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "    optimizer.zero_grad()\n",
    "    # Training loop\n",
    "    for epoch in range(epochs):\n",
    "        losses = []\n",
    "        accuracies = []\n",
    "        \n",
    "        \n",
    "        random.shuffle(batches_x)\n",
    "        for batch in batches_x:\n",
    "              # Zero the gradients\n",
    "            target_batch = batch[:, 1:]  # Target sequence (exclude first token)\n",
    "            zeroes = torch.zeros(batch.shape[0], 1, dtype=torch.long)\n",
    "            target_batch = torch.cat((target_batch, zeroes), dim=1)\n",
    "\n",
    "            # Forward pass\n",
    "            predictions = model(batch)\n",
    "            # Calculate loss\n",
    "            loss = criterion(predictions.reshape(-1, len(w2i)), target_batch.reshape(-1))\n",
    "            # Backward pass and optimization\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            losses.append(loss.item())\n",
    "            predictions = predictions.argmax(dim=2)\n",
    "            print(f'predictions: {predictions}, target: {target_batch}')\n",
    "            # calculate accuracy: number of correct predictions / number of predictions\n",
    "            n_correct = (predictions == target_batch).sum().item()\n",
    "            accuracy = n_correct / (predictions.shape[0]*predictions.shape[1])\n",
    "            print(f'accuracy: {accuracy}')\n",
    "            accuracies.append(accuracy)\n",
    "        \n",
    "        if do_seed:\n",
    "            seed(model)\n",
    "\n",
    "        # Print the average loss for the epoch\n",
    "        print('Epoch: ', epoch, 'Loss: ', np.mean(losses), 'Accuracy: ', np.mean(accuracies))  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  0 Loss:  0.14719433334185714 Accuracy:  0.98875\n",
      "Epoch:  1 Loss:  6.06505567908755e-07 Accuracy:  1.0\n",
      "Epoch:  2 Loss:  0.0 Accuracy:  1.0\n",
      "Epoch:  3 Loss:  0.0 Accuracy:  1.0\n",
      "Epoch:  4 Loss:  0.0 Accuracy:  1.0\n"
     ]
    }
   ],
   "source": [
    "model = AutoregressiveLSTM(len(w2i))\n",
    "train(batches_x[:1000], model, epochs=5, lr=0.001, optimizer='Adam')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.distributions as dist\n",
    "def sample(lnprobs, temperature=1.0):\n",
    "    if temperature == 0.0:\n",
    "        return lnprobs.argmax()\n",
    "    \n",
    "    p = torch.nn.functional.softmax(lnprobs / temperature, dim=0)\n",
    "    cd = dist.Categorical(p)\n",
    "    \n",
    "    return cd.sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed(model):\n",
    "    for _ in range(10):  # Generate 10 sequences after each epoch\n",
    "\n",
    "        seed_sequence = [w2i['.start'], w2i['('], w2i['('], w2i[')']]\n",
    "        seed_input = torch.tensor([seed_sequence], dtype=torch.long)\n",
    "\n",
    "        # Generate samples\n",
    "        max_length = 30  # Maximum sequence length\n",
    "        generated_sequence = seed_sequence.copy()\n",
    "\n",
    "        while True:\n",
    "            output_logits = model(seed_input)\n",
    "            next_token_logits = output_logits[0, -1, :]\n",
    "            next_token_index = sample(next_token_logits, temperature=0.5)  # Adjust temperature as needed\n",
    "\n",
    "            generated_sequence.append(next_token_index.item())\n",
    "            if next_token_index.item() == w2i['.end'] or len(generated_sequence) >= max_length:\n",
    "                break\n",
    "\n",
    "            seed_input = torch.tensor([generated_sequence], dtype=torch.long)\n",
    "\n",
    "        # Convert indices back to tokens and print the generated sequence\n",
    "        generated_sequence_tokens = [i2w[index] for index in generated_sequence]\n",
    "        print('Generated Sequence:', ' '.join(generated_sequence_tokens))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 4, 5, 2] [1, 4, 5, 2] [1, 4, 5, 2]\n"
     ]
    }
   ],
   "source": [
    "x_train, (i2w, w2i) = load_brackets(n=150_000)\n",
    "batches_x = padding(x_train, w2i)\n",
    "print(x_train[0], x_train[1000], x_train[10000])\n",
    "model = AutoregressiveLSTM(len(w2i))\n",
    "# train(batches_x, model, epochs=5, lr=0.001, optimizer='Adam', do_seed=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
